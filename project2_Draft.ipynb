{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6b3fd2d",
   "metadata": {},
   "source": [
    "# COMP90051 Project 2\n",
    "**Name:** *Kechen Zhao*\n",
    "\n",
    "**Student ID:** *957398*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "iraqi-recommendation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can add additional imports here\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eef77e3",
   "metadata": {},
   "source": [
    "## 0. Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "concerned-vessel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not edit this cell\n",
    "# load the data files (download from the LMS)\n",
    "embedded_images = np.load('images.npy')\n",
    "labels = np.load('labels.npy')\n",
    "\n",
    "# split into pool & testing\n",
    "X_pool, X_test, y_pool, y_test = train_test_split(embedded_images, labels, \n",
    "                                                  test_size=0.5, random_state=1234, shuffle=True)\n",
    "\n",
    "# sample a seed set\n",
    "np.random.seed(1234)\n",
    "label2id = defaultdict(list)\n",
    "for i, label in enumerate(y_pool):\n",
    "    label2id[label].append(i)\n",
    "seed_set = []\n",
    "for label, ids in label2id.items():\n",
    "    seed_set.extend(np.random.choice(ids, size=10, replace=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "f95d1df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed set\n",
    "seed_X = []\n",
    "seed_y = []\n",
    "for index in seed_set:\n",
    "    seed_X.append(X_pool[index])\n",
    "    seed_y.append(y_pool[index])\n",
    "# seed_X = pd.DataFrame(seed_X)\n",
    "# seed_y = pd.DataFrame(seed_y).loc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "6066ae50",
   "metadata": {},
   "outputs": [],
   "source": [
    "U_X = []\n",
    "U_y = []\n",
    "L_X = []\n",
    "L_y = []\n",
    "for index in range(len(X_pool)):\n",
    "        if index not in seed_set:\n",
    "            U_X.append(X_pool[index])\n",
    "            U_y.append(y_pool[index])\n",
    "        else:\n",
    "            L_X.append(X_pool[index])\n",
    "            L_y.append(y_pool[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "2bd8fc57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'node_id': 598, 'left': 596, 'right': 597}"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "clustering = AgglomerativeClustering(n_clusters=30).fit(seed_X)\n",
    "ii = itertools.count(len(seed_X))\n",
    "tree = [{'node_id': next(ii), 'left': x[0], 'right':x[1]} for x in clustering.children_]\n",
    "tree[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "fed584e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'AgglomerativeClustering' object has no attribute 'distance_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-380-05bf66506246>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# show the plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m#pyplot.show()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistance_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'AgglomerativeClustering' object has no attribute 'distance_'"
     ]
    }
   ],
   "source": [
    "# agglomerative clustering\n",
    "from numpy import unique\n",
    "from numpy import where\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# define the model\n",
    "model = AgglomerativeClustering(n_clusters=30)\n",
    "# fit model and predict clusters\n",
    "yhat = model.fit_predict(seed_X)\n",
    "# retrieve unique clusters\n",
    "clusters = unique(yhat)\n",
    "# create scatter plot for samples from each cluster\n",
    "for cluster in clusters:\n",
    "    # get row indexes for samples with this cluster\n",
    "    row_ix = where(yhat == cluster)\n",
    "    # create scatter of these samples\n",
    "    #pyplot.scatter(X[row_ix, 0], X[row_ix, 1])\n",
    "# show the plot\n",
    "#pyplot.show()\n",
    "model.distance_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naval-income",
   "metadata": {},
   "source": [
    "## 1. Applying logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "palestinian-preparation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def train_logistic_regression(X, y, **args):\n",
    "def train_logistic_regression(X, y, penalty, tol, C, max_iter, solver):\n",
    "    \"\"\"\n",
    "    Train a logistic regression model on dataset (X, y) and return trained model.\n",
    "    X: matrix of real values, size n x d\n",
    "    y: vector of string labels, size n\n",
    "    args: optional arguments e.g., for hyper-parameters\n",
    "    \"\"\"\n",
    "    # your code here\n",
    "    \n",
    "    model = LogisticRegression(penalty='none',tol = tol, C = C, multi_class='multinomial', solver=solver, max_iter = max_iter)\n",
    "    model.fit(X, y)\n",
    "#     intercept = model.intercept_\n",
    "#     coefficient = model.coef_.squeeze()\n",
    "#     parameters = []\n",
    "#     parameters.append(intercept)\n",
    "#     parameters.append(coefficient)\n",
    "    return model\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "bored-alberta",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_logistic_regression_accuracy(Xt, yt, model):\n",
    "    \"\"\"\n",
    "    Apply logistic regression prediction on dataset Xt and evaluate accuracy against yt,\n",
    "    returing the accuracy results as a scalar.\n",
    "    Xt: matrix of real values, size m x d\n",
    "    yt: vector of string labels, size m\n",
    "    \"\"\"\n",
    "    # your code here\n",
    "    \n",
    "    logmod = model\n",
    "    #logmod.fit(Xt, yt)\n",
    "    y_pred = logmod.predict(Xt)\n",
    "    scores = metrics.accuracy_score(yt, y_pred)\n",
    "    \n",
    "    return scores\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "79acfb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameter setup\n",
    "penalty = 'none'\n",
    "tol = 0.0001\n",
    "C = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "c9a99933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy trained based on seed set: 0.312551867219917\n",
      "CPU times: user 40.4 s, sys: 186 ms, total: 40.6 s\n",
      "Wall time: 40.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = train_logistic_regression(seed_X, np.array(seed_y), penalty, tol, C, 100000, 'sag')\n",
    "accuracy = evaluate_logistic_regression_accuracy(X_test, y_test, model)\n",
    "print(\"Accuracy trained based on seed set:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "whole-grenada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified version for query committee\n",
    "\n",
    "def pool_based_active_learning(X_pool, y_pool, seed_ids,\n",
    "                               train_func, select_func,\n",
    "                               max_size, batch_size, select_method, query_method, **args):\n",
    "    \"\"\"\n",
    "    Perform an active learning simulation, which starts by training on a seed set,\n",
    "    then iteratively applies the selection function to rank instances in the pool,\n",
    "    selects the top few instances which are included into the training set and the\n",
    "    process repeats. \n",
    "        X_pool: matrix of n x d\n",
    "        y_pool: vector of string labels, size n\n",
    "        seed_ids: initial labelled set set, as a list of indices [0..n-1] into pool\n",
    "        train_func: function which given (X, y, optional args) returns a trained model\n",
    "        select_func: function which given (X, optional args) returns a sequence of scores\n",
    "        max_size: stopping condition for active learning, when labelled data reaches given size\n",
    "        batch_size: number of instances to be labelled in each iteration\n",
    "        args: optional arguments passed to training and selection function\n",
    "    returns the sequence of trained models \n",
    "    \"\"\"\n",
    "  \n",
    "    # fill in\n",
    "    \n",
    "    # construct U, the pool of unlabelled instances and their hidden labels\n",
    "    U_X = []\n",
    "    U_y = []\n",
    "    # construct L, the set of initial labelled instances\n",
    "    L_X = []\n",
    "    L_y = []\n",
    "    \n",
    "    for index in range(len(X_pool)):\n",
    "        if index not in seed_ids:\n",
    "            U_X.append(X_pool[index])\n",
    "            U_y.append(y_pool[index])\n",
    "        else:\n",
    "            L_X.append(X_pool[index])\n",
    "            L_y.append(y_pool[index])\n",
    "#     L_X = pd.DataFrame(L_X)\n",
    "#     L_y = pd.DataFrame(L_y).loc[:,0]\n",
    "\n",
    "    \n",
    "    b = batch_size\n",
    "    T = int(max_size/batch_size)\n",
    "    labels = set(y_pool)\n",
    "    \n",
    "    for t in range(0, T):\n",
    "        # selection method\n",
    "        if select_method == \"query_by_committee\":\n",
    "            ensemble1, ensemble2, logmod = train_committee(np.array(L_X), np.array(L_y), 'none', 0.0001, 1.0, 20, 'sag')\n",
    "            theta_t = logmod\n",
    "            if query_method == \"vote_entropy\":\n",
    "                model = [ensemble1, ensemble2]\n",
    "                r = select_func(U_X, model, labels)\n",
    "            else:\n",
    "                model = [ensemble1, ensemble2]\n",
    "                r = select_func(U_X, model)\n",
    "        else:\n",
    "            theta_t = train_func(np.array(L_X), np.array(L_y), 'none', 0.0001, 1.0, 20, 'sag')\n",
    "            r = select_func(U_X, theta_t) # random_select\n",
    "            \n",
    "        # find the indices of top b instances in r\n",
    "        max_index = []\n",
    "        for i in range(b):\n",
    "            max_index.append(r.index(max(r)))\n",
    "            r[r.index(max(r))] = 0\n",
    "\n",
    "        for j in max_index:\n",
    "            x_j = U_X[j]\n",
    "            L_X.append(np.array(x_j))\n",
    "            U_X[j] = []\n",
    "            y_j = U_y[j]\n",
    "            L_y.append(np.array(y_j))\n",
    "            U_y[j] = np.nan\n",
    "\n",
    "        U_X = list(np.array(pd.DataFrame(U_X).dropna()))\n",
    "        U_y = list(pd.DataFrame(U_y).dropna().loc[:,0])\n",
    "\n",
    "    return theta_t\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "50c5c9af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9280\n",
      "9220\n",
      "Accuracy trained based on vote entropy selection with max_size 120: 0.3386929460580913\n",
      "9280\n",
      "9220\n",
      "9160\n",
      "9100\n",
      "9040\n",
      "Accuracy trained based on vote entropy selection with max_size 300: 0.3809128630705394\n",
      "9280\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-355-2608f6519917>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msize\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msize_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmax_size\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     models_us = pool_based_active_learning(X_pool, y_pool, seed_set, \n\u001b[0m\u001b[1;32m      6\u001b[0m                                      \u001b[0mtrain_committee\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                                      \u001b[0mquery_by_committee_vote_entropy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-354-f0459b7c55d9>\u001b[0m in \u001b[0;36mpool_based_active_learning\u001b[0;34m(X_pool, y_pool, seed_ids, train_func, select_func, max_size, batch_size, select_method, query_method, **args)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mU_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mU_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;31m#         for instance in U_X:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    568\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mis_named_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m                         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fields\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m                     \u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m                     \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mto_arrays\u001b[0;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[1;32m    526\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# columns if columns is not None else []\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_list_to_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoerce_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m         return _list_of_dict_to_arrays(\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_list_to_arrays\u001b[0;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_or_indexify_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_object_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoerce_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_convert_object_array\u001b[0;34m(content, coerce_float, dtype)\u001b[0m\n\u001b[1;32m    734\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    734\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(arr)\u001b[0m\n\u001b[1;32m    730\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"O\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m             \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_convert_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtry_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_cast_to_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# vote_entropy\n",
    "accuracy_vote_entropy = []\n",
    "for size in size_list:\n",
    "    max_size  = size\n",
    "    models_us = pool_based_active_learning(X_pool, y_pool, seed_set, \n",
    "                                     train_committee, \n",
    "                                     query_by_committee_vote_entropy, \n",
    "                                     max_size, batch, \"query_by_committee\", \"vote_entropy\")\n",
    "    score = evaluate_logistic_regression_accuracy(X_test, y_test, models_us)\n",
    "    accuracy_vote_entropy.append(score)\n",
    "    print(f\"Accuracy trained based on vote entropy selection with max_size {size}:\", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerical-novel",
   "metadata": {},
   "source": [
    "## 3. Uncertainty sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "raised-mistress",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_entropy_select(X, model, **args):\n",
    "    \"\"\"\n",
    "    Given an unlabelled dataset X, a matrix of n x d, and a discriminative model \n",
    "    P(y|x), returns a vector of n entropy values.\n",
    "    \n",
    "    Should use intercept and coefficients from logistic regression to calculate the probability\n",
    "    for each class y we have the corresponding intercept and coefficients\n",
    "    \n",
    "    X will be served as Data Frame\n",
    "    \n",
    "    \"\"\"\n",
    "    # fill in\n",
    "    \n",
    "    entropy = [];\n",
    "    intercept = model.intercept_\n",
    "    coefficient = model.coef_.squeeze()\n",
    "    \n",
    "    for instance in X:\n",
    "        score = 0\n",
    "        for i in range(len(intercept)):\n",
    "            t = np.dot(coefficient[i], instance) + intercept[i]\n",
    "            prob = 1/(1+np.exp(-t))\n",
    "            score = score + prob*np.log(prob)\n",
    "        entropy.append(-score)\n",
    "        \n",
    "    return entropy\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "optical-mount",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here for evaluation of accuracy and plotting of results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diverse-taxation",
   "metadata": {},
   "source": [
    "## 4. Query by committee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "61b6d9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_by_committee_vote_entropy(X, model, labels, **args):\n",
    "    \n",
    "    \"\"\"\n",
    "    Given an unlabelled dataset X, a matrix of n x d, and a discriminative model \n",
    "    P(y|x), returns a vector of n vote entropy values.\n",
    "    \n",
    "    C = number of models\n",
    "    \n",
    "    Need to use C number of models to predict instances in X.\n",
    "    Then for different classes of y, calculate the vote and sum them up.\n",
    "    Assume argument model contains two models. \n",
    "    \n",
    "    Arugment 'labels': a list of unique possible labels\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    X = pd.DataFrame(X)\n",
    "    vote_entropy = []\n",
    "    \n",
    "    # get members in committee\n",
    "    model1 = model[0]\n",
    "    model2 = model[1]\n",
    "    \n",
    "    # use models to make predictions on the unlabelled dataset X\n",
    "    classification1 = model1.predict(X)\n",
    "    classification2 = model2.predict(X)\n",
    "    \n",
    "\n",
    "    # loop over each instances in X, calculate their corresponding vote entropy\n",
    "    for i in range(len(X)):\n",
    "        \n",
    "        # create a dictionary to track the vote\n",
    "        dic = dict.fromkeys(labels, 0)\n",
    "        \n",
    "        predic1 = classification1[i]\n",
    "        predic2 = classification2[i]\n",
    "        \n",
    "        dic[predic1] = dic[predic1] + 1\n",
    "        dic[predic2] = dic[predic2] + 1\n",
    "        \n",
    "        entropy = 0\n",
    "        for vote in dic.values():\n",
    "            if vote != 0:\n",
    "                entropy = entropy + (vote/2)*np.log(vote/2)\n",
    "            \n",
    "        vote_entropy.append(-entropy)\n",
    "        \n",
    "    return vote_entropy\n",
    "\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "handy-water",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # don't forget to provide function descriptive comments, like those provided in templates above\n",
    "\n",
    "# def query_by_committee_vote_entropy(X, model, **args):\n",
    "#     pass\n",
    "\n",
    "# def query_by_committee_soft_vote_entropy(X, model, **args):\n",
    "#     pass\n",
    "\n",
    "# def query_by_committee_KL(X, model, **args):\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "continued-clothing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_committee(X, y, penalty, tol, C, max_iter, solver):\n",
    "    \n",
    "    \"\"\"\n",
    "    Train a logistic regression model on dataset (X, y) and return trained model.\n",
    "    X: matrix of real values, size n x d\n",
    "    y: vector of string labels, size n\n",
    "    args: optional arguments e.g., for hyper-parameters\n",
    "    C: number of models in committee\n",
    "    ensemble_type: type of ensemble functions, e.g. LogisticRegressoin, SVM\n",
    "    Could return two models:\n",
    "    – the ensemble and the standard logistic regression model as a tuple \n",
    "    i.e., return (model1, model2)\n",
    "    \"\"\"\n",
    "\n",
    "    ensemble1 = svm.SVC(probability=True, max_iter=200)\n",
    "    ensemble1.fit(X,y)\n",
    "    \n",
    "    ensemble2 = LogisticRegression(multi_class='multinomial', max_iter = 20, solver='saga')\n",
    "    ensemble2.fit(X,y)\n",
    "        \n",
    "    logmod = LogisticRegression(penalty='none',tol = tol, C = C, multi_class='multinomial', solver=solver, max_iter = max_iter)\n",
    "    logmod.fit(X,y)\n",
    "    \n",
    "    return (ensemble1, ensemble2, logmod)\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "c2835e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_list = [120, 300, 600, 900, 1200, 1500, 1800, 2100, 2400, 2700, 3000]\n",
    "batch = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "d71be42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9280\n",
      "9220\n",
      "Accuracy trained based on vote entropy selection with max_size 120: 0.3411825726141079\n",
      "9280\n",
      "9220\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'numpy.ndarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-345-2608f6519917>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msize\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msize_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmax_size\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     models_us = pool_based_active_learning(X_pool, y_pool, seed_set, \n\u001b[0m\u001b[1;32m      6\u001b[0m                                      \u001b[0mtrain_committee\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                                      \u001b[0mquery_by_committee_vote_entropy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-344-f5bda8c625ed>\u001b[0m in \u001b[0;36mpool_based_active_learning\u001b[0;34m(X_pool, y_pool, seed_ids, train_func, select_func, max_size, batch_size, select_method, query_method, **args)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;31m# selection method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mselect_method\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"query_by_committee\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mensemble1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensemble2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_committee\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'none'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sag'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0mtheta_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogmod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mquery_method\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"vote_entropy\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-268-5a46a3bccdcf>\u001b[0m in \u001b[0;36mtrain_committee\u001b[0;34m(X, y, penalty, tol, C, max_iter, solver)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mensemble1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobability\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mensemble1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mensemble2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmulti_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'multinomial'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'saga'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    171\u001b[0m                                        accept_large_sparse=False)\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         sample_weight = np.asarray([]\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_validate_targets\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m         self.class_weight_ = compute_class_weight(self.class_weight,\n\u001b[0m\u001b[1;32m    556\u001b[0m                                                   classes=cls, y=y_)\n\u001b[1;32m    557\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\u001b[0m in \u001b[0;36mcompute_class_weight\u001b[0;34m(class_weight, classes, y)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         raise ValueError(\"classes should include all valid labels that can \"\n\u001b[1;32m     45\u001b[0m                          \"be in y\")\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'"
     ]
    }
   ],
   "source": [
    "# vote_entropy\n",
    "accuracy_vote_entropy = []\n",
    "for size in size_list:\n",
    "    max_size  = size\n",
    "    models_us = pool_based_active_learning(X_pool, y_pool, seed_set, \n",
    "                                     train_committee, \n",
    "                                     query_by_committee_vote_entropy, \n",
    "                                     max_size, batch, \"query_by_committee\", \"vote_entropy\")\n",
    "    score = evaluate_logistic_regression_accuracy(X_test, y_test, models_us)\n",
    "    accuracy_vote_entropy.append(score)\n",
    "    print(f\"Accuracy trained based on vote entropy selection with max_size {size}:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "dadf2f2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.fromstring('0', dtype=int, sep=' ')\n",
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "south-smooth",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here for training, evaluation, and plotting code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suffering-airport",
   "metadata": {},
   "source": [
    "## 5. Hierarchical sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adopted-taylor",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
